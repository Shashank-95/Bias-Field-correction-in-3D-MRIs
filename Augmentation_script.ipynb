{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"New_Augmentation_2020.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNdtuVFVZEtYK8S5UUKUR5m"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RXBLnLxlidCT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1597447418193,"user_tz":420,"elapsed":25778,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"47e6f761-8f77-402b-d5d8-d9da889e60d9"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","\n","import numpy as np\n","from sklearn.utils import shuffle\n","import nibabel as nib \n","import glob\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","!pip install nilearn\n","import nilearn as nil\n","import cv2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Collecting nilearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/c2/f5f1bdd37a3da28b3b34305e4ba27cce468db6073998d62a38abd0e281da/nilearn-0.6.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (3.0.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.18.5)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.16.0)\n","Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.2.post1)\n","Installing collected packages: nilearn\n","Successfully installed nilearn-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZRPdqPLfj0_N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1596304026020,"user_tz":420,"elapsed":354,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"03a14c43-d860-4bd0-f6a4-ecd02fdbbd82"},"source":["#Read training set\n","corr_imgs = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Corrected Dataset/*')) \n","labels = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/*'))\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/BiasField_acpc_dc (1).nii.gz',\n"," 'drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/BiasField_acpc_dc (10).nii.gz',\n"," 'drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/BiasField_acpc_dc (11).nii.gz',\n"," 'drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/BiasField_acpc_dc (12).nii.gz',\n"," 'drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/BiasField_acpc_dc (13).nii.gz']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"vlBxULdaj6fT","colab_type":"code","colab":{}},"source":["N = 64\n","total_imgs = 0\n","\n","# Take each labels multiply with 40 skull stripped bias corrected images\n","\n","for l in range(len(labels)): # Iterating through each label\n","  label = []\n","  a = nib.load(labels[l])\n","  a = a.get_fdata()\n","  for k in range(a.shape[0]):                                                                                                  \n","    temp = cv2.resize(a[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(a.shape[1]):                                                                                                  \n","    temp = cv2.resize(a[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(a.shape[2]):                                                                                                  \n","    temp = cv2.resize(a[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","  \n","  label = np.asarray(label)  \n","  label = label.reshape(-1,N,N,1)  # (260 * 64 * 64 * 1)\n","\n","  for c in range(len(corr_imgs)): # Iterating through corrected images\n","    image = []\n","    a = nib.load(corr_imgs[c])\n","    a = a.get_fdata()\n","\n","    for k in range(a.shape[0]):                                                                                                  \n","      temp = cv2.resize(a[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                          \n","      image.append(temp)\n","\n","    for k in range(a.shape[1]):                                                                                                  \n","      temp = cv2.resize(a[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                          \n","      image.append(temp)\n","\n","    for k in range(a.shape[2]):                                                                                                  \n","      temp = cv2.resize(a[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                          \n","      image.append(temp)\n","    \n","    image = np.asarray(image) \n","    image = image.reshape(-1,N,N,1)  # (260 * 64 * 64 * 1)\n","\n","    #for i in range(len(label)):  \n","    #  for j in range(N):\n","    #    for k in range(N):\n","    #      if (image[i,j,k,0] == 0):  # Based on Skull Stripped image, making the bias zero\n","    #        label[i,j,k,0] = 0  \n","\n","    temp_img = np.multiply(label,image) # Element wise multiplication of bias and corrected MRI  \n","\n","    final_img = np.empty([260,311,260]) # converting the image from (260 * 64 * 64 * 1) to (260*311*260)\n","    for idx in range(0,260):\n","      img = temp_img[idx, :, :,0]\n","      img_resized = cv2.resize(img, (260, 311), interpolation=cv2.INTER_CUBIC)\n","      final_img[idx,:,:] = img_resized\n","\n","    total_imgs = total_imgs + 1\n","\n","    # Saving Images in respective folder\n","    final_img = nil.image.new_img_like(nib.load(corr_imgs[c]),final_img,copy_header=True)\n","    nib.save(final_img,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Test_Set/TestImages/' + 'input_train-' + str(total_imgs) + '.nii.gz')\n","    \n","    just_for_ref_corr = nib.load(corr_imgs[c]).get_fdata()\n","    just_for_ref_corr = nil.image.new_img_like(nib.load(corr_imgs[c]),just_for_ref_corr, copy_header=True)\n","    nib.save(just_for_ref_corr,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Test_Set/TestCorrected_GroundTruth/'  + 'corrected_train-'  + str(total_imgs) +'.nii.gz')\n","  \n","    label_save = nib.load(labels[l]).get_fdata()\n","    label_save = nil.image.new_img_like(nib.load(labels[l]),label_save,copy_header=True)\n","    nib.save(label_save,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Test_Set/TestLabels/'  + 'label_train-'  + str(total_imgs) +'.nii.gz')\n","  \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9r84WP8zorkv","colab_type":"code","colab":{}},"source":["N= 64\n","\n","# Uncompress the Augmented Images to .npz format\n","imgs = sorted(glob.glob('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Training_Set/Images_nii_gz/*'))\n","labels = sorted(glob.glob('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Training_Set/Labels_nii_gz/*'))\n","\n","#For Labels\n","for l in range(len(labels)): # Iterating through each label\n","  label = []\n","  a = nib.load(labels[l])\n","  a = a.get_fdata()\n","  for k in range(a.shape[0]):                                                                                                  \n","    temp = cv2.resize(a[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(a.shape[1]):                                                                                                  \n","    temp = cv2.resize(a[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(a.shape[2]):                                                                                                  \n","    temp = cv2.resize(a[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  label = np.asarray(label)\n","  label = label.reshape(-1,N,N,1) \n","\n","  np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Training_Set/Labels_npz/label-'+ str(l+1) + '.npz', label)\n","\n","\n","# For Images\n","for l in range(len(imgs)): # Iterating through each label\n","  image = []\n","  a = nib.load(imgs[l])\n","  a = a.get_fdata()\n","  for k in range(a.shape[0]):                                                                                                  \n","    temp = cv2.resize(a[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    image.append(temp)\n","\n","  for k in range(a.shape[1]):                                                                                                  \n","    temp = cv2.resize(a[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    image.append(temp)\n","\n","  for k in range(a.shape[2]):                                                                                                  \n","    temp = cv2.resize(a[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    image.append(temp)\n","\n","  image = np.asarray(image)\n","  image = image.reshape(-1,N,N,1) \n","  np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/Training_Set/Images_npz/input-'+ str(l+1) + '.npz', image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zScBvwmJnJH","colab_type":"code","colab":{}},"source":["imgs = sorted(glob.glob('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/InputImages_npz/*'))\n","labels = sorted(glob.glob('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/Labels_npz/*'))\n","\n","\n","#Finding minimum and Maximum values in images\n","Max = float(\"-inf\")\n","Min = float(\"inf\")\n","for i in range(len(imgs)):\n","  images = np.load(imgs[i])['arr_0']\n","\n","  if (np.max(images) > Max):\n","    Max = np.max(images)\n","\n","  if (np.min(images) < Min):\n","    Min = np.min(images)\n","\n","\n","#Finding minimum and Maximum values in labels\n","Max_lab = float(\"-inf\")\n","Min_lab = float(\"inf\")\n","\n","for i in range(len(labels)):\n","  lab = np.load(labels[i])['arr_0']\n","\n","  if (np.max(lab) > Max_lab):\n","    Max_lab = np.max(lab)\n","\n","  if (np.min(lab) < Min_lab):\n","    Min_lab = np.min(lab)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-g8_2ftYZTD","colab_type":"code","colab":{}},"source":["#Normalize Images\n","Max_norm  = 0\n","Min_norm  = 0\n","\n","for i in range(len(imgs)):\n","  images = np.load(imgs[i])['arr_0']\n","  images = (images - Min) / (Max - Min)\n","  if (np.max(images) > Max_norm):\n","    Max_norm = np.max(images)\n","\n","  if (np.min(images) < Min_norm):\n","    Min_norm = np.min(images) \n","\n","  #print(Max_norm, \"  \", Min_norm)\n","  np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/InputImages_npz_normalize/' + imgs[i][124:] , images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3VFyJK1rZDMd","colab_type":"code","colab":{}},"source":["#Normalize Labels\n","Max_norm  = 0\n","Min_norm  = 0\n","\n","for i in range(len(labels)):\n","\n","  lab = np.load(labels[i])['arr_0']\n","\n","  lab = (lab - Min_lab) / (Max_lab - Min_lab)\n","  \n","  if (np.max(images) > Max_norm):\n","    Max_norm = np.max(lab)\n","\n","  if (np.min(images) < Min_norm):\n","    Min_norm = np.min(lab) \n","\n"," # print(Max_norm, \"  \", Min_norm)\n","\n","  np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/Labels_npz_normalize/' + labels[i][119:] , lab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJtoMb2UkTxG","colab_type":"code","colab":{}},"source":["#Let's stop this and do it in my way\n","corr_imgs = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Corrected Dataset/*'))   #reading corr mris\n","labels = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/*')) # reading labels\n","labels = labels[5:40]\n","total_imgs = 0\n","N = 64\n","for l in range(len(labels)): # Iterating through each label\n","  \n","  biasField = nib.load(labels[l])\n","  biasField = biasField.get_fdata()\n","\n","  label = []\n","  for k in range(biasField.shape[0]):                                                                                                  \n","    temp = cv2.resize(biasField[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(biasField.shape[1]):                                                                                                  \n","    temp = cv2.resize(biasField[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  for k in range(biasField.shape[2]):                                                                                                  \n","    temp = cv2.resize(biasField[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","    label.append(temp)\n","\n","  label = np.asarray(label)\n","  label = label.reshape(-1,N,N,1)\n","\n","  for c in range(len(corr_imgs)): # Iterating through corrected images\n","    image = []\n","    corrImage = nib.load(corr_imgs[c])\n","    corrImage = corrImage.get_fdata()\n","\n","    InputImage = np.multiply(biasField, corrImage)\n","    total_imgs = total_imgs +1\n","\n","    image = []\n","    for k in range(InputImage.shape[0]):                                                                                                  \n","      temp = cv2.resize(InputImage[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","      image.append(temp)\n","\n","    for k in range(InputImage.shape[1]):                                                                                                  \n","      temp = cv2.resize(InputImage[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","      image.append(temp)\n","\n","    for k in range(InputImage.shape[2]):                                                                                                  \n","      temp = cv2.resize(InputImage[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR)                                            \n","      image.append(temp)\n","\n","    image = np.asarray(image)\n","    image = image.reshape(-1,N,N,1)\n","  \n","    np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/Labels_npz/'+'label-train'+ str(total_imgs) + '.npz', label)\n","    np.savez_compressed('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TrainAgain/InputImages_npz/'+'input-train'+ str(total_imgs) + '.npz', image)\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fPvHoSTnCyy","colab_type":"code","colab":{}},"source":["#Test Set -- Let's stop this and do it in my way \n","corr_imgs = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Corrected Dataset/*'))   #reading corr mris\n","labels = sorted(glob.glob('drive/My Drive/Research/Augmented Dataset/Model_Output_Bias_images/*')) # reading labels\n","labels = labels[:5]\n","total_imgs = 0\n","N = 64\n","for l in range(len(labels)): # Iterating through each label\n","  \n","  biasField = nib.load(labels[l])\n","  biasField = biasField.get_fdata()\n","\n","  for c in range(len(corr_imgs)): # Iterating through corrected images\n","    corrImage = nib.load(corr_imgs[c])\n","    corrImage = corrImage.get_fdata()\n","\n","    InputImage = np.multiply(biasField, corrImage)\n","    total_imgs = total_imgs +1\n","\n","    # Saving Images in respective folder\n","    InputImage = nil.image.new_img_like(nib.load(corr_imgs[c]),InputImage, copy_header=True)\n","    nib.save(InputImage,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TestAgain/Images/' + 'input_train-' + str(total_imgs) + '.nii.gz')\n","    \n","    just_for_ref_corr = nib.load(corr_imgs[c]).get_fdata()\n","    just_for_ref_corr = nil.image.new_img_like(nib.load(corr_imgs[c]),just_for_ref_corr, copy_header=True)\n","    nib.save(just_for_ref_corr,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TestAgain/CorrectedImages/'  + 'corrected_train-'  + str(total_imgs) +'.nii.gz')\n","  \n","    label_save = nib.load(labels[l]).get_fdata()\n","    label_save = nil.image.new_img_like(nib.load(labels[l]),label_save,copy_header=True)\n","    nib.save(label_save,'drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/Augment_MRI_Images/Lets_start_again/TestAgain/Labels/'  + 'label_train-'  + str(total_imgs) +'.nii.gz')\n","  \n","\n","\n"],"execution_count":null,"outputs":[]}]}
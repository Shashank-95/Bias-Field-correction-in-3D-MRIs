{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Augment_training_2020.ipynb","provenance":[{"file_id":"1VLoY8sFRmGMUkf0DvSenuWFLpzk4GW9O","timestamp":1583900358600}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"djJ95qT_i-ko","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596515813131,"user_tz":420,"elapsed":943,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"7b1a5bc8-ce32-4f6a-a9f2-e5f0bb052fc2"},"source":["PROJECT_ID = \"plated-monolith-205220\" #@param {type:\"string\"}\n","! gcloud config set project $PROJECT_ID"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iwOfUwhsYrzL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596515814709,"user_tz":420,"elapsed":56,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"68d5bf96-2f4b-4a3d-e461-e0ae7b1146e9"},"source":["import sys\n","\n","# If you are running this notebook in Colab, run this cell and follow the\n","# instructions to authenticate your GCP account. This provides access to your\n","# Cloud Storage bucket and lets you submit training jobs and prediction\n","# requests.\n","\n","if 'google.colab' in sys.modules:  \n","  from google.colab import auth as google_auth\n","  google_auth.authenticate_user()\n","\n","# If you are running this notebook locally, replace the string below with the\n","# path to your service account key and run this cell to authenticate your GCP\n","# account.\n","else:\n","  %env GOOGLE_APPLICATION_CREDENTIALS ''"],"execution_count":2,"outputs":[{"output_type":"stream","text":["env: GOOGLE_APPLICATION_CREDENTIALS=''\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SFHyliBV4PnQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1596515824191,"user_tz":420,"elapsed":7481,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"e479789a-25ee-42e8-ae0c-d57232527aca"},"source":["import numpy as np\n","from sklearn.utils import shuffle\n","import nibabel as nib #reading MR images\n","import glob\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","!pip install nilearn\n","import nilearn\n","!pip install h5py\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nilearn in /usr/local/lib/python3.5/dist-packages (0.6.2)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.5/dist-packages (from nilearn) (1.4.1)\n","Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.5/dist-packages (from nilearn) (3.0.2)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.5/dist-packages (from nilearn) (0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.5/dist-packages (from nilearn) (0.14.1)\n","Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.5/dist-packages (from nilearn) (0.22.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.5/dist-packages (from nilearn) (1.18.1)\n","\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2 is available.\n","You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/nilearn/__init__.py:68: FutureWarning: Python 3.5 support is deprecated and will be removed in a future release. Consider switching to Python 3.6 or 3.7\n","  _python_deprecation_warnings()\n"],"name":"stderr"},{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from h5py) (1.12.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from h5py) (1.18.1)\n","\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2 is available.\n","You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qx9lSPKcK4NZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596515835824,"user_tz":420,"elapsed":323,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"acd1b63b-d26c-4b1f-9ec0-d2ea7dbc73c4"},"source":["from sklearn.model_selection import train_test_split\n","\n","filenames = sorted(glob.glob('./Training/Images/*'))\n","labels = sorted(glob.glob('./Training/Labels/*'))\n","\n","from sklearn.utils import shuffle\n","\n","filenames , labels = shuffle(filenames, labels)\n","\n","X_train_filenames, X_val_filenames, y_train, y_val = train_test_split(\n","    filenames, labels, test_size=0.2, random_state=1)\n","\n","print(\"Training Set Size: \", len(X_train_filenames), \" MRIs\")\n","print(\"Validation Set Size: \", len(X_val_filenames), \" MRIs\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Training Set Size:  1120  MRIs\n","Validation Set Size:  280  MRIs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nNBoLJbI_LaD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596500672800,"user_tz":420,"elapsed":62,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"9c529298-c1f1-49e8-bba6-d9e887d778aa"},"source":["len(filenames)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1400"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"xzV1DJ4YdFwk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596500674091,"user_tz":420,"elapsed":274,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"e061a8cd-ea04-4e44-ef19-474d59192059"},"source":["temp1 = np.load(filenames[0])['arr_0']\n","temp2 = np.load(filenames[1])['arr_0']\n","\n","temp = np.concatenate((temp1,temp2))\n","print(temp.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1662, 64, 64, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y54mD2LwNo2G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596515847335,"user_tz":420,"elapsed":7824,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"252739de-5cb1-4a05-fb43-7668fbd33c08"},"source":["import keras\n","import cv2\n","class My_Custom_Generator(keras.utils.Sequence) :  \n","  \n","  def __init__(self, image_filenames, labels, batch_size) :\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n","  \n","  \n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","\n","    N = 64 \n","    images = np.load(batch_x[0])['arr_0']\n","    for f in range(1,len(batch_x)):\n","      temp = np.load(batch_x[f])['arr_0']\n","      images = np.concatenate((images,temp))\n","\n","    # maximum = np.max(images)    \n","    # minimum = np.min(images)\n","    # images = (images - minimum) / (maximum - minimum)\n","\n","    labels = np.load(batch_x[0])['arr_0']\n","    for f in range(1,len(batch_y)):\n","      temp = np.load(batch_y[f])['arr_0']\n","      labels = np.concatenate((labels,temp))\n","\n","    # m = np.max(labels) \n","    # mi = np.min(labels)\n","    # labels = (labels - mi) / (m - mi)\n","\n","    for i in range(len(labels)):\n","      for j in range(N):\n","        for k in range(N):\n","          if (images[i,j,k,0] == 0): #images array contains data from skull striped images; \n","            labels[i,j,k,0] = 0 #this is done to set those pixel values that are outside the brain in the images ground truth to 0\n","\n","    return images, labels\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n-0EHaM-cuGV","colab":{}},"source":["# inst = My_Custom_Generator(X_train_filenames, y_train, 32)\n","# img, lab = inst.__getitem__(1)\n","\n","# print(np.shape(img),np.shape(lab))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1y5AABpiduG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596515851759,"user_tz":420,"elapsed":62,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}}},"source":["import os\n","import cv2\n","from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import Model,Sequential\n","#from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n","from keras.losses import mean_absolute_error,mean_squared_error\n","from keras import regularizers\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2l3MHteht68","colab_type":"code","colab":{}},"source":["# batch_size = 256\n","# epochs = 100\n","inChannel = 1\n","N=64\n","x, y = N, N\n","input_img = Input(shape = (x, y, inChannel))\n","\n","def autoencoder(input_img):\n","  \n","    #encoder\n","    \n","    conv1 = Conv2D(12, (7, 7), activation='relu', padding='same')(input_img) # N x N x 12\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(12, (7, 7), activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n","\n","    conv2 = Conv2D(24, (7, 7), activation='relu', padding='same')(pool1) # N/2 x N/2 x 24\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(24, (7, 7), activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2) \n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #14 x 14 x 32\n","    \n","    conv3 = Conv2D(48, (7, 7), activation='relu', padding='same')(pool2) # N/4 x N/4 x 24\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(48, (7, 7), activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3) \n","\n","    #decoder\n","\n","    conv4 = Conv2D(48, (7, 7), activation='relu', padding='same')(conv3) # N/2 x N/2 x 24\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(48, (7, 7), activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4) \n","    \n","    up1 = UpSampling2D((2,2))(conv4) \n","\n","    conv5 = Conv2D(24, (7, 7), activation='relu', padding='same')(up1) # N/2 x N/2 x 24\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(24, (7, 7), activation='relu', padding='same')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    \n","    up2 = UpSampling2D((2,2))(conv5) \n","    \n","    conv6 = Conv2D(12, (7, 7), activation='relu', padding='same')(up2) # N x N x 12\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Conv2D(12, (7, 7), activation='relu', padding='same')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(conv6) # N x N x 1\n","    return decoded\n","\n","autoencoder = Model(input_img, autoencoder(input_img))\n","autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop()) #a better metric (instead of mean squared error) to verify the performance would be \n","autoencoder.summary()                                                 #to feed the corrected MRI images in Brainsuite and find out if the segmentation of the brain \n","                                                                      #tissues is done right\n","\n","#Create Checkpoints\n","filepath=\"./Model/Intermediate_V2/weights-best_last.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only = False)\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eEjFuT61swm2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596515880207,"user_tz":420,"elapsed":1025,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}}},"source":["autoencoder.load_weights(\"./Model/Intermediate_V2/weights-best_last.hdf5\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzVSKIanN7fn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1596533708124,"user_tz":420,"elapsed":17822323,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}},"outputId":"3f206710-b6f0-446a-a44d-b1d3f63e9424"},"source":["batch_size = 2\n","\n","my_training_batch_generator = My_Custom_Generator(X_train_filenames, y_train, batch_size)\n","my_validation_batch_generator = My_Custom_Generator(X_val_filenames, y_val, 2)\n","\n","\n","## Define our model here.\n","\n","autoencoder_train = autoencoder.fit_generator(generator = my_training_batch_generator,\n","                   steps_per_epoch =  int(len(X_train_filenames) // batch_size),\n","                   epochs = 5,\n","                   verbose = 1,\n","                   callbacks = callbacks_list,\n","                   validation_data = my_validation_batch_generator,\n","                   validation_steps = int(len(X_val_filenames) // 2))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/5\n","560/560 [==============================] - 4446s 8s/step - loss: 0.0012 - val_loss: 0.0018\n","\n","Epoch 00001: val_loss improved from inf to 0.00179, saving model to ./Model/Intermediate_V2/weights-best_last.hdf5\n","Epoch 2/5\n","560/560 [==============================] - 3313s 6s/step - loss: 0.0012 - val_loss: 0.0036\n","\n","Epoch 00002: val_loss did not improve from 0.00179\n","Epoch 3/5\n","560/560 [==============================] - 3366s 6s/step - loss: 0.0012 - val_loss: 0.0047\n","\n","Epoch 00003: val_loss did not improve from 0.00179\n","Epoch 4/5\n","560/560 [==============================] - 3338s 6s/step - loss: 0.0012 - val_loss: 0.0021\n","\n","Epoch 00004: val_loss did not improve from 0.00179\n","Epoch 5/5\n","560/560 [==============================] - 3356s 6s/step - loss: 0.0011 - val_loss: 0.0010\n","\n","Epoch 00005: val_loss improved from 0.00179 to 0.00103, saving model to ./Model/Intermediate_V2/weights-best_last.hdf5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dgNI8mrafpdk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596533782126,"user_tz":420,"elapsed":144,"user":{"displayName":"Shashank Nelamangala Sridhara","photoUrl":"","userId":"10721712378063584589"}}},"source":["autoencoder.save(\"./Model/Intermediate_V2/final_model.h5\")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iEoSG9E4peT","colab_type":"code","colab":{}},"source":["loss = autoencoder_train.history['loss']\n","val_loss = autoencoder_train.history['val_loss']\n","epochs = range(5)\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss in x direction')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xF_iZgVu43lw","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(16, 4))\n","print(\"Ground truth for the Test Images\")\n","#Displaying the first five images from the ground truth of the test images\n","\n","for i in range(5):\n","    plt.subplot(1, 5, i+1)\n","    plt.imshow(valid_ground[i+200,:,:,0],cmap='gray')                                               #plt.imshow(valid_ground[i+200, ..., 205], cmap='gray')\n","plt.show()    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiVQ3SE843vv","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(16, 4))\n","print(\"Reconstruction of Bias field from the training dataset\")\n","#Displaying the first five images from the prediction made by the auto encoder on the test images\n","for i in range(5):\n","    plt.subplot(1, 5, i+1)\n","    plt.imshow(pred[i+200,:,:,0],cmap='gray')                                                                                           #plt.imshow(pred[i, ..., 0], cmap='gray')  \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzwQ_6Ym43YY","colab_type":"code","colab":{}},"source":["autoencoder.save('drive/My Drive/DR_NonUniformityCorrection/Augmented_Training/augmented_model.h5') \n","#to save the weights of the trained model"],"execution_count":null,"outputs":[]}]}